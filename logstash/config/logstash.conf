input { 
    stdin { }
} 
filter {
    csv { 
        separator => ","
        columns => ["camis","dba","boro","building","street","zipcode","phone","cuisine-description","inspection-date","action","violation-code","violation-description","critical-flag","score","grade","grade-date","record-date","inspection-type"]
        skip_empty_columns => true
    }
    mutate {
        rename => { "@timestamp" => "imported-date" }   
    }   
    date {
        match => [ "record-date", "MM/dd/yyyy" ]
        target => "@timestamp"
    }
    date {
        match => [ "record-date", "MM/dd/yyyy" ]
        target => "record-date"
    }
    date {
        match => [ "inspection-date", "MM/dd/yyyy" ]
        target => "inspection-date"
    }
    date {
        match => [ "grade-date", "MM/dd/yyyy" ]
        target => "grade-date"
    }
    mutate {
        convert => {
            zipcode => "integer"
        }
    }

    translate {
        field => "zipcode"
        dictionary_path => "/files/ny_zips.yaml"
   }

    mutate {
        gsub => [
            "translation", " ", ""
        ]
        split => {"translation" => ","}
    }

    mutate {
        add_field => ["latitude","%{[translation[0]}"]
        add_field => ["longitude","%{[translation[1]}"]
    }

    mutate {
        convert => { "longitude" => "float" }
        convert => { "latitude" => "float" }
    }

    mutate {
        rename => {
            "longitude" => "[location][lon]"
            "latitude" => "[location][lat]"
        }
    }

    mutate {
        remove_field => "translation"
    }
}
output { 
    #stdout { codec => rubydebug }
    elasticsearch {
       hosts => ["http://elasticsearch.local:9200"]
       index => "dohmh"
       document_type => "log"
       flush_size => 2500
       template => "/files/dohmh.template.json"
       template_name => "dohmh"
       template_overwrite => true
       manage_template => true
    }
}